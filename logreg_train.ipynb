{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57a2d618",
        "outputId": "1bdd490f-c5a2-406d-b1e0-a57f1e811005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "id": "57a2d618"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bab6cd0"
      },
      "source": [
        "### Data Load and Preprocessing "
      ],
      "id": "9bab6cd0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f0a3c72",
        "outputId": "c2f11489-9276-4d08-a5c6-5faf5a273516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    79152\n",
              " 1.0    72356\n",
              "-1.0    17232\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/CS410Project/train_data.csv', low_memory=False)\n",
        "data['sentiment'].value_counts()"
      ],
      "id": "4f0a3c72"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ff5df33"
      },
      "outputs": [],
      "source": [
        "def process(text) : # remove capitalization, stopwords, and punctuation\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@[^\\s]+', '', text) # remove username\n",
        "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE) # remove http link\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    procList = [word for word in nopunc.split() if word not in stopwords.words('english')]\n",
        "    return ' '.join(procList)\n",
        "\n",
        "data['text'] = data['text'].apply(lambda row: process(row))\n",
        "\n",
        "data = data[['text', 'sentiment']]\n",
        "data = data[data['sentiment'].notna()]\n"
      ],
      "id": "4ff5df33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d41989eb"
      },
      "source": [
        "### Train/Test/Validation Split"
      ],
      "id": "d41989eb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2da9d2b9"
      },
      "outputs": [],
      "source": [
        "import scipy.sparse as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "id": "2da9d2b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da519187",
        "outputId": "a0d5871c-def0-4b13-e4e6-2fa3978c6ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118118,) (118118,)\n",
            "(25311,) (25311,)\n",
            "(25311,) (25311,)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(data['text'], data['sentiment'], test_size=0.3, random_state=42)\n",
        "x_test, x_valid, y_test, y_valid = train_test_split(x_valid,y_valid, test_size=0.5, random_state=42)\n",
        "y_train = y_train.fillna(0)\n",
        "y_valid = y_valid.fillna(0)\n",
        "y_test = y_test.fillna(0)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "id": "da519187"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87603bc2",
        "outputId": "2cf23a22-563a-437a-fa5f-402427224b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8018                             eeenf new highs todayðŸš€ðŸš€ðŸš€ðŸš€ðŸš€\n",
              "83665     rt earn bitcoins using google chrome bitcoin f...\n",
              "129028    hate vs coreblockstream bs propaganda thats ca...\n",
              "46148                          sii think im done see ya 290\n",
              "127826            best chart analyst bitcoin live 2 minutes\n",
              "                                ...                        \n",
              "3686                                 ttcm real nft play fyi\n",
              "160977    eth ethereum blockchain smartcontracts crypto ...\n",
              "65188     coinbase talks buy one bitcoins best funded st...\n",
              "39597     ltc giveaway ill giving 05 ltc 1 lucky followe...\n",
              "93199     name metaverse etp symbol etp 24 hour change 1...\n",
              "Name: text, Length: 25311, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_test"
      ],
      "id": "87603bc2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e136277a"
      },
      "source": [
        "### Binary Bag-of-Words / TF-IDF Representation and Cross-validation splits"
      ],
      "id": "e136277a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a4ad252"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# max_vocab = 3000\n",
        "# bow_transformer = CountVectorizer(max_features=max_vocab, ngram_range=(1,2), binary=True ).fit(x_train.values.astype('U'))\n",
        "# x_train = bow_transformer.transform(x_train.values.astype('U'))\n",
        "# x_valid = bow_transformer.transform(x_valid.values.astype('U'))\n",
        "# x_test = bow_transformer.transform(x_test.values.astype('U'))"
      ],
      "id": "5a4ad252"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e736efe"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "max_vocab = 4000\n",
        "tfidf_transformer = TfidfVectorizer(max_features=max_vocab, ngram_range=(1,2)).fit(x_train.values.astype('U'))\n",
        "x_train = tfidf_transformer.transform(x_train.values.astype('U'))\n",
        "x_valid = tfidf_transformer.transform(x_valid.values.astype('U'))\n",
        "x_test = tfidf_transformer.transform(x_test.values.astype('U'))\n"
      ],
      "id": "1e736efe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "608cb33a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "\n",
        "my_test_fold = []\n",
        "for i in range(x_train.shape[0]):\n",
        "    my_test_fold.append(-1)\n",
        "for i in range(x_valid.shape[0]):\n",
        "    my_test_fold.append(0)\n",
        "\n",
        "fold = PredefinedSplit(test_fold=my_test_fold)\n",
        "y_cv = np.append(y_train, y_valid)\n",
        "x_cv = sp.vstack((x_train , x_valid)) "
      ],
      "id": "608cb33a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12993871"
      },
      "source": [
        "### Hyperparameter value search "
      ],
      "id": "12993871"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f64a32e",
        "outputId": "a4576746-582a-4de4-eb7c-ae4aab77be68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 90.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def cross_val(parameters, x, y, fold): \n",
        "    n_folds = 5\n",
        "    logreg = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter = 15000, dual=False)\n",
        "    logreg_cv = GridSearchCV(logreg, parameters, cv=fold, scoring=\"f1_macro\", refit=False)\n",
        "    logreg_cv.fit(x, y) \n",
        "    scores = logreg_cv.cv_results_['mean_test_score']\n",
        "    params = logreg_cv.cv_results_['params']\n",
        "    return logreg_cv.best_params_\n",
        "\n",
        "values = [ 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "scale = 5\n",
        "c_optimal = None\n",
        "previous_best = 100000\n",
        "while True: \n",
        "    param_grid = {'C': values}\n",
        "    best_params = cross_val(param_grid, x_cv, y_cv, fold)\n",
        "    current_best = best_params['C']\n",
        "    if (abs(current_best - previous_best ) > .0001) : \n",
        "        increment = current_best/10\n",
        "        lower_bound = current_best - increment*scale\n",
        "        upper_bound = current_best + increment*scale\n",
        "        values = np.arange(lower_bound, upper_bound, increment)\n",
        "        previous_best = current_best\n",
        "    else : \n",
        "        c_optimal = current_best\n",
        "        break\n",
        "\n",
        "print(f'Best C: {c_optimal}')"
      ],
      "id": "3f64a32e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2da2e3"
      },
      "source": [
        "### Train With Detected Hyperparameter and Predict on Test Set"
      ],
      "id": "6e2da2e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34b619a8",
        "outputId": "3cde3339-82cb-469f-c7a2-4c8a2a7a83c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0    55332\n",
            " 1.0    50712\n",
            "-1.0    12074\n",
            "Name: sentiment, dtype: int64\n",
            " 0.0    60566\n",
            " 1.0    48375\n",
            "-1.0     9177\n",
            "dtype: int64\n",
            "\t Training accuracy: \t \t 0.8606224284190386\n",
            "\t Training balanced accuracy: \t 0.7969818925701193\n",
            "\t Training F1: \t \t \t 0.8606224284190386\n",
            " 0.0    11843\n",
            " 1.0    10943\n",
            "-1.0     2525\n",
            "Name: sentiment, dtype: int64\n",
            " 0.0    12980\n",
            " 1.0    10431\n",
            "-1.0     1900\n",
            "dtype: int64\n",
            "\t Test accuracy: \t \t 0.8479712378017463\n",
            "\t Test balanced accuracy: \t 0.7780522723688735\n",
            "\t Test F1: \t \t \t 0.8479712378017463\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, average_precision_score\n",
        "\n",
        "\n",
        "logreg = LogisticRegression(C=c_optimal, multi_class='ovr', solver='liblinear',  max_iter = 15000, dual=False)\n",
        "logreg.fit(x_train, y_train)\n",
        "\n",
        "y_hat_train = logreg.predict(x_train)\n",
        "    \n",
        "print(y_train.value_counts())\n",
        "print(pd.Series(y_hat_train).value_counts())\n",
        "print('\\t Training accuracy: \\t \\t', accuracy_score(y_train, y_hat_train)  )\n",
        "print('\\t Training balanced accuracy: \\t', balanced_accuracy_score(y_train, y_hat_train)  )\n",
        "print('\\t Training F1: \\t \\t \\t', f1_score(y_train, y_hat_train, average='micro')  )\n",
        "\n",
        "#predict on test set\n",
        "y_hat_test = logreg.predict(x_test)\n",
        "print(y_test.value_counts())\n",
        "print(pd.Series(y_hat_test).value_counts())\n",
        "print('\\t Test accuracy: \\t \\t', accuracy_score(y_test, y_hat_test)  )\n",
        "print('\\t Test balanced accuracy: \\t', balanced_accuracy_score(y_test, y_hat_test)  )\n",
        "print('\\t Test F1: \\t \\t \\t', f1_score(y_test, y_hat_test, average='micro')  )\n"
      ],
      "id": "34b619a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a0fe646"
      },
      "source": [
        "### Train LogReg on full set and save model state / tf-idf transformer"
      ],
      "id": "1a0fe646"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49a3202d",
        "outputId": "f7a20990-7131-4f80-daf6-4ac90355e0d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=90.0, max_iter=15000, multi_class='ovr',\n",
              "                   solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tfidf_transformer = TfidfVectorizer(max_features=max_vocab, ngram_range=(1,2)).fit(data['text'].values.astype('U'))\n",
        "x_train = tfidf_transformer.transform(data['text'].values.astype('U'))\n",
        "\n",
        "logreg = LogisticRegression(C=c_optimal, multi_class='ovr', solver='liblinear',  max_iter = 15000, dual=False)\n",
        "logreg.fit(x_train, data['sentiment'].fillna(0))"
      ],
      "id": "49a3202d"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a7477dcc"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('logreg.pkl', 'wb') as f: \n",
        "    pickle.dump(logreg, f)\n",
        "    \n",
        "with open('tfidf_transformer.pkl', 'wb') as f: \n",
        "    pickle.dump(tfidf_transformer, f)"
      ],
      "id": "a7477dcc"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}